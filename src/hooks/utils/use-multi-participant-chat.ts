'use client';

import { useChat } from '@ai-sdk/react';
import type { UIMessage } from 'ai';
import { DefaultChatTransport } from 'ai';
import { useCallback, useLayoutEffect, useMemo, useRef, useState } from 'react';
import { flushSync } from 'react-dom';
import { z } from 'zod';

import type { ChatParticipant } from '@/api/routes/chat/schema';
import { chatParticipantSelectSchema } from '@/db/validation/chat';
import { ParticipantSettingsSchema } from '@/lib/config/participant-settings';
import type { UIMessageErrorType } from '@/lib/utils/message-transforms';
import { createErrorUIMessage, mergeParticipantMetadata } from '@/lib/utils/message-transforms';
import { deduplicateParticipants } from '@/lib/utils/participant-utils';
import { calculateNextRoundNumber, getCurrentRoundNumber } from '@/lib/utils/round-utils';

import { useParticipantErrorTracking } from './use-participant-error-tracking';

/**
 * Full ChatParticipant schema with settings
 * Matches the ChatParticipant type from the API routes
 */
const ChatParticipantSchema = chatParticipantSelectSchema
  .extend({
    settings: ParticipantSettingsSchema,
  });

/**
 * Zod schema for UseMultiParticipantChatOptions validation
 * Validates hook options at entry point to ensure type safety
 * Note: Callbacks are not validated to preserve their type signatures
 */
const UseMultiParticipantChatOptionsSchema = z
  .object({
    threadId: z.string(), // Allow empty string for initial state
    participants: z.array(ChatParticipantSchema).min(0, 'Participants must be an array'),
    messages: z.array(z.custom<UIMessage>()).optional(),
    mode: z.string().optional(),
    regenerateRoundNumber: z.number().int().positive().optional(),
  })
  .passthrough(); // Allow callbacks to pass through without validation

/**
 * Options for configuring the multi-participant chat hook
 */
type UseMultiParticipantChatOptions = {
  /** The current chat thread ID */
  threadId: string;
  /** All participants (enabled and disabled) */
  participants: ChatParticipant[];
  /** Initial messages for the chat (optional) */
  messages?: UIMessage[];
  /** Callback when a round completes (all enabled participants have responded) */
  onComplete?: () => void;
  /** Callback when user clicks retry (receives the round number being retried) */
  onRetry?: (roundNumber: number) => void;
  /** Callback when an error occurs */
  onError?: (error: Error) => void;
  /** Chat mode (e.g., 'moderator', 'standard') */
  mode?: string;
  /** When set, indicates this is a round regeneration */
  regenerateRoundNumber?: number;
};

/**
 * Return value from the multi-participant chat hook
 */
type UseMultiParticipantChatReturn = {
  /** All messages in the conversation */
  messages: UIMessage[];
  /** Send a new user message and start a round */
  sendMessage: (content: string) => Promise<void>;
  /** Start a new round with the existing participants (used for manual round triggering) */
  startRound: () => void;
  /** Whether participants are currently streaming responses */
  isStreaming: boolean;
  /** The index of the currently active participant */
  currentParticipantIndex: number;
  /** Any error that occurred during the chat */
  error: Error | null;
  /** Retry the last round (regenerate entire round from scratch - deletes all messages and re-sends user prompt) */
  retry: () => void;
  /** Stop the current streaming session */
  stop: () => void;
  /** Manually set messages (used for optimistic updates or message deletion) */
  setMessages: (messages: UIMessage[] | ((messages: UIMessage[]) => UIMessage[])) => void;
  /** Reset all hook state (error tracking) */
  resetHookState: () => void;
};

/**
 * Multi-Participant Chat Hook - Simplified Orchestration for AI Conversations
 *
 * Coordinates multiple AI participants responding sequentially to user messages.
 * Simplified to trust backend for round tracking and participant management.
 *
 * The hook maintains minimal client state and delegates complex logic to the backend,
 * following the FLOW_DOCUMENTATION.md principle of backend authority.
 *
 * AI SDK v5 Pattern: Message Metadata Flow
 * ========================================
 *
 * 1. STREAMING STATE (no metadata yet):
 *    - Message is being generated by AI SDK
 *    - No model/participant metadata available yet
 *    - UI uses currentParticipantIndex to show correct avatar/name
 *    - flushSync ensures index updates before next participant streams
 *
 * 2. ON FINISH (metadata added):
 *    - AI SDK calls onFinish with complete message
 *    - mergeParticipantMetadata adds: model, participantId, participantIndex, role, roundNumber
 *    - flushSync ensures metadata is committed BEFORE next participant starts
 *    - This prevents UI from showing wrong participant info during streaming
 *
 * 3. COMPLETED STATE (has metadata):
 *    - Message has full metadata from backend
 *    - UI trusts saved metadata and ignores currentParticipantIndex
 *    - No re-rendering when currentParticipantIndex changes
 *
 * CRITICAL SYNCHRONIZATION POINTS:
 * --------------------------------
 * 1. Before triggering next participant: flushSync(setCurrentParticipantIndex)
 * 2. After finishing current participant: flushSync(setMessages with metadata)
 * 3. These ensure React commits state BEFORE triggering next API call
 *
 * Without flushSync, React batches updates and causes:
 * - Wrong participant avatars/names during streaming
 * - Message UI flickering between participants
 * - Completed messages showing as streaming
 *
 * @example
 * const chat = useMultiParticipantChat({
 *   threadId: 'thread-123',
 *   participants: [
 *     { id: '1', modelId: 'gpt-4', isEnabled: true, priority: 0 },
 *     { id: '2', modelId: 'claude-3', isEnabled: true, priority: 1 },
 *   ],
 *   onComplete: () => {
 *     // Round complete callback
 *   }
 * });
 *
 * await chat.sendMessage("What's the best way to learn React?");
 */
export function useMultiParticipantChat(
  options: UseMultiParticipantChatOptions,
): UseMultiParticipantChatReturn {
  // Validate critical options at hook entry point (excluding callbacks to preserve types)
  const validationResult = UseMultiParticipantChatOptionsSchema.safeParse(options);

  if (!validationResult.success) {
    throw new Error(`Invalid hook options: ${validationResult.error.message}`);
  }

  const {
    threadId,
    participants,
    messages: initialMessages = [],
    onComplete,
    onRetry,
    onError,
    mode,
    regenerateRoundNumber: regenerateRoundNumberParam,
  } = options;

  const errorTracking = useParticipantErrorTracking();

  // Track regenerate round number for backend communication
  const regenerateRoundNumberRef = useRef<number | null>(regenerateRoundNumberParam || null);

  // Simple round tracking state - backend is source of truth
  const [_currentRound, setCurrentRound] = useState(1);
  const currentRoundRef = useRef<number>(1);

  // Simple participant state - index-based iteration
  const [currentParticipantIndex, setCurrentParticipantIndex] = useState(0);
  const [isExplicitlyStreaming, setIsExplicitlyStreaming] = useState(false);

  // Participant refs for round stability
  const participantsRef = useRef<ChatParticipant[]>(participants);
  const roundParticipantsRef = useRef<ChatParticipant[]>([]);
  const currentIndexRef = useRef<number>(currentParticipantIndex);

  // Track if we're currently triggering to prevent double triggers
  const isTriggeringRef = useRef<boolean>(false);

  // Refs to hold values needed for triggering (to avoid closure issues in callbacks)
  const messagesRef = useRef<UIMessage[]>([]);
  const aiSendMessageRef = useRef<((message: { text: string; metadata?: Record<string, unknown> }) => void) | null>(null);

  /**
   * Trigger the next participant using refs (safe to call from useChat callbacks)
   */
  const triggerNextParticipantWithRefs = useCallback(() => {
    // Prevent double triggers
    if (isTriggeringRef.current) {
      return;
    }

    const nextIndex = currentIndexRef.current + 1;
    const totalParticipants = roundParticipantsRef.current.length;

    // AI SDK v5 Pattern: Round Complete - Last Participant Callback
    // When the last participant finishes, trigger the completion callback
    // This callback is used to invoke analysis stream after ALL participants complete
    if (nextIndex >= totalParticipants) {
      setIsExplicitlyStreaming(false);
      errorTracking.reset();
      regenerateRoundNumberRef.current = null;
      setCurrentParticipantIndex(0);

      // ✅ CRITICAL FIX: Use TRIPLE requestAnimationFrame to ensure AI SDK state propagates
      // Race condition: Even double rAF wasn't enough - messages state from useChat needs more time
      // First rAF: Waits for browser paint after last participant's message metadata is added
      // Second rAF: Ensures messages state from useChat has updated
      // Third rAF: Ensures messagesRef has been synced via useLayoutEffect with ALL participant messages
      // This prevents analysis from being created with incomplete participant message IDs (N-1 bug)
      // See: use-analysis-creation.ts:245-254 for similar pattern
      requestAnimationFrame(() => {
        requestAnimationFrame(() => {
          requestAnimationFrame(() => {
            onComplete?.();
          });
        });
      });

      return;
    }

    // More participants to process - trigger next one
    isTriggeringRef.current = true;

    // CRITICAL: Update ref BEFORE setting state to avoid race condition
    // The prepareSendMessagesRequest reads from currentIndexRef.current
    // so we must update it synchronously before calling aiSendMessage
    currentIndexRef.current = nextIndex;

    // CRITICAL FIX: Use flushSync to ensure participant index update is committed BEFORE triggering next participant
    // Without flushSync, React batches this state update and may re-render with the new index
    // before the first participant's message metadata is properly evaluated, causing both messages
    // to show the second participant's icon/name during the batched render.
    // AI SDK v5 Pattern: Prevents UI from showing wrong participant info during sequential streaming
    // eslint-disable-next-line react-dom/no-flush-sync -- Required for multi-participant chat synchronization
    flushSync(() => {
      setCurrentParticipantIndex(nextIndex);
    });

    // Find the last user message using ref
    const lastUserMessage = messagesRef.current.findLast((m: UIMessage) => m.role === 'user');
    if (!lastUserMessage) {
      // Restore to previous index on error
      currentIndexRef.current = currentIndexRef.current - 1;
      isTriggeringRef.current = false;
      return;
    }

    const textPart = lastUserMessage.parts?.find((p: { type: string; text?: string }) => p.type === 'text' && 'text' in p);
    const userText = textPart && 'text' in textPart ? String(textPart.text || '') : '';

    if (!userText.trim()) {
      // Restore to previous index on error
      currentIndexRef.current = currentIndexRef.current - 1;
      isTriggeringRef.current = false;
      return;
    }

    // Trigger next participant immediately using ref
    // The transport's prepareSendMessagesRequest will read currentIndexRef.current
    if (aiSendMessageRef.current) {
      aiSendMessageRef.current({
        text: userText,
        metadata: { roundNumber: currentRoundRef.current, isParticipantTrigger: true },
      });
    }

    // AI SDK v5 Pattern: Use requestAnimationFrame instead of setTimeout
    // This resets trigger lock after the browser's next paint cycle
    requestAnimationFrame(() => {
      isTriggeringRef.current = false;
    });
  }, [errorTracking, onComplete]);

  /**
   * Prepare request body for AI SDK chat transport
   *
   * AI SDK v5 Pattern: Use callback to access refs safely
   * Refs should only be accessed in callbacks/effects, not during render
   */
  const prepareSendMessagesRequest = useCallback(
    ({ id, messages }: { id: string; messages: unknown[] }) => {
      // Access ref inside callback (safe) instead of during useMemo initialization
      const body = {
        id,
        message: messages[messages.length - 1],
        participantIndex: currentIndexRef.current, // ✅ Safe: accessed in callback, not render
        participants: participantsRef.current, // ✅ Safe: accessed in callback, not render
        ...(regenerateRoundNumberRef.current && { regenerateRound: regenerateRoundNumberRef.current }),
        ...(mode && { mode }),
      };

      return { body };
    },
    [mode],
  );

  // AI SDK v5 Pattern: Create transport with callback that accesses refs safely
  // The prepareSendMessagesRequest callback is invoked by the transport at request time (not during render),
  // so accessing refs inside the callback is safe and follows the recommended pattern from AI SDK documentation.
  // The callback is stable (only depends on 'mode') and refs are only accessed during callback invocation.
  const transport = useMemo(
    () =>
      // eslint-disable-next-line react-hooks/refs -- Callback is invoked at request time, not during render
      new DefaultChatTransport({
        api: '/api/v1/chat',
        prepareSendMessagesRequest,
      }),
    [prepareSendMessagesRequest],
  );

  const {
    messages,
    sendMessage: aiSendMessage,
    status,
    error: chatError,
    setMessages,
    stop,
  } = useChat({
    id: threadId,
    transport,
    // AI SDK v5 Pattern: Pass messages (renamed from initialMessages in v5.0)
    // When provided from backend after thread creation, these hydrate the chat
    // Reference: https://github.com/vercel/ai/blob/ai_5_0_0/content/docs/08-migration-guides/26-migration-guide-5-0.mdx
    ...(initialMessages && initialMessages.length > 0 ? { messages: initialMessages } : {}),

    /**
     * Handle participant errors - create error UI and continue to next participant
     */
    onError: (error) => {
      // CRITICAL: Use ref for current index to avoid stale closure
      const currentIndex = currentIndexRef.current;
      const participant = roundParticipantsRef.current[currentIndex];

      // Parse error metadata if present
      let errorMessage = error instanceof Error ? error.message : String(error);
      let errorMetadata: Record<string, unknown> | undefined;

      try {
        if (typeof errorMessage === 'string' && (errorMessage.startsWith('{') || errorMessage.includes('errorCategory'))) {
          errorMetadata = JSON.parse(errorMessage) as Record<string, unknown>;
          if (errorMetadata?.errorMessage) {
            errorMessage = errorMetadata.errorMessage as string;
          }
        }
      } catch {
        // Invalid JSON - use original error message
      }

      // Create error message UI only if not already responded
      if (participant) {
        const errorKey = `${participant.modelId}-${currentIndex}`;

        if (!errorTracking.hasResponded(errorKey)) {
          errorTracking.markAsResponded(errorKey);

          const errorUIMessage = createErrorUIMessage(
            participant,
            currentIndex,
            errorMessage,
            (errorMetadata?.errorCategory as UIMessageErrorType) || 'error',
            errorMetadata,
            currentRoundRef.current,
          );

          setMessages(prev => [...prev, errorUIMessage]);
        }
      }

      // Trigger next participant immediately (no delay needed)
      triggerNextParticipantWithRefs();
      onError?.(error instanceof Error ? error : new Error(errorMessage));
    },

    /**
     * Handle successful participant response
     * AI SDK v5 Pattern: Trust the SDK's built-in deduplication
     */
    onFinish: async (data) => {
      // CRITICAL: Use ref for current index to avoid stale closure
      const currentIndex = currentIndexRef.current;
      const participant = roundParticipantsRef.current[currentIndex];

      // Handle silent failure (no message object from AI SDK)
      if (!data.message) {
        if (participant) {
          const errorKey = `${participant.modelId}-${currentIndex}`;

          // Only create error message if not already tracked
          if (!errorTracking.hasResponded(errorKey)) {
            errorTracking.markAsResponded(errorKey);

            const errorUIMessage = createErrorUIMessage(
              participant,
              currentIndex,
              'This model failed to generate a response. The AI SDK did not create a message object.',
              'silent_failure',
              { providerMessage: 'No response text available' },
              currentRoundRef.current,
            );

            setMessages(prev => [...prev, errorUIMessage]);
          }
        }

        // Trigger next participant immediately
        triggerNextParticipantWithRefs();
        const error = new Error(`Participant ${currentIndex} failed: data.message is missing`);
        onError?.(error);
        return;
      }

      // AI SDK v5 Pattern: ALWAYS update message metadata on finish
      // The AI SDK adds the message during streaming; we update it with proper metadata
      if (participant && data.message) {
        const updatedMetadata = mergeParticipantMetadata(
          data.message,
          participant,
          currentIndex,
        );

        // Prefer backend round number, fallback to current state
        const backendRoundNumber = (data.message.metadata as Record<string, unknown> | undefined)?.roundNumber as number | undefined;
        const finalRoundNumber = backendRoundNumber || currentRoundRef.current;

        const metadataWithRoundNumber = {
          ...updatedMetadata,
          roundNumber: finalRoundNumber,
        };

        // Use flushSync to force React to commit metadata update synchronously
        // AI SDK v5 Pattern: Prevents race conditions between sequential participants
        // eslint-disable-next-line react-dom/no-flush-sync -- Required for multi-participant chat synchronization
        flushSync(() => {
          setMessages((prev) => {
            const completeMessage: UIMessage = {
              ...data.message,
              metadata: metadataWithRoundNumber,
            };

            // CRITICAL FIX: Check if message exists AND belongs to current participant
            // AI SDK can reuse message IDs across participants, so we must verify participant ownership
            const existingMessageIndex = prev.findIndex((msg: UIMessage) => {
              if (msg.id !== data.message.id)
                return false;

              // Check if this message already belongs to a different participant
              const msgMetadata = msg.metadata as Record<string, unknown> | undefined;
              const msgParticipantId = msgMetadata?.participantId as string | undefined;
              const msgParticipantIndex = msgMetadata?.participantIndex as number | undefined;

              // If message has participant metadata, verify it matches current participant
              if (msgParticipantId || msgParticipantIndex !== undefined) {
                return msgParticipantId === participant.id || msgParticipantIndex === currentIndex;
              }

              // Message has no participant metadata yet - it's safe to claim
              return true;
            });

            if (existingMessageIndex === -1) {
              // Message doesn't exist or belongs to different participant - add new message
              return [...prev, completeMessage];
            }

            // Update existing message with complete metadata (verified to be same participant)
            return prev.map((msg: UIMessage, idx: number) => {
              if (idx === existingMessageIndex) {
                return completeMessage;
              }
              return msg;
            });
          });
        });

        // Track this response to prevent duplicate error messages
        const responseKey = `${participant.modelId}-${currentIndex}`;
        errorTracking.markAsResponded(responseKey);
      }

      // CRITICAL: Wait for browser paint before triggering next participant
      // flushSync above ensures React commits the metadata update
      // requestAnimationFrame ensures the browser paints the update
      // THEN we trigger the next participant
      // This prevents the second participant from showing before the first participant's metadata is visible
      requestAnimationFrame(() => {
        triggerNextParticipantWithRefs();
      });
    },
  });

  /**
   * Sync participants ref with latest participants
   */
  useLayoutEffect(() => {
    participantsRef.current = participants;
  }, [participants]);

  /**
   * Keep refs in sync with latest values from useChat
   */
  useLayoutEffect(() => {
    messagesRef.current = messages;
    aiSendMessageRef.current = aiSendMessage;
  }, [messages, aiSendMessage]);

  /**
   * AI SDK v5 Pattern: NO manual message syncing needed
   *
   * According to the AI SDK v5 crash course (Exercise 01.07, 04.02, 04.03):
   * - initialMessages are passed to useChat on mount ONLY via the initialMessages prop
   * - When threadId changes, useChat naturally re-initializes its state
   * - No manual setMessages calls needed for thread changes
   * - Trust AI SDK's built-in state management
   *
   * The previous useLayoutEffect that synced initialMessages was incorrect and caused issues
   * with chat initialization. It's been removed to follow the official AI SDK v5 pattern.
   */

  /**
   * Start a new round with existing participants
   *
   * AI SDK v5 Pattern: Used when initializing a thread with existing messages
   * (e.g., from backend after thread creation) and need to trigger streaming
   * for the first participant. This is the pattern from Exercise 01.07, 04.02, 04.03.
   */
  const startRound = useCallback(() => {
    if (status !== 'ready' || isExplicitlyStreaming) {
      return;
    }

    const uniqueParticipants = deduplicateParticipants(participants);
    const enabled = uniqueParticipants.filter(p => p.isEnabled);

    if (enabled.length === 0) {
      return;
    }

    const lastUserMessage = messages.findLast(m => m.role === 'user');

    if (!lastUserMessage) {
      return;
    }

    const textPart = lastUserMessage.parts?.find(p => p.type === 'text' && 'text' in p);
    const userText = textPart && 'text' in textPart ? textPart.text : '';

    if (!userText.trim()) {
      return;
    }

    const roundNumber = getCurrentRoundNumber(messages);

    // CRITICAL: Update refs FIRST to avoid race conditions
    // These refs are used in prepareSendMessagesRequest and must be set before the API call
    currentIndexRef.current = 0;
    roundParticipantsRef.current = enabled;
    isTriggeringRef.current = false;
    currentRoundRef.current = roundNumber;

    // Reset all state for new round
    setIsExplicitlyStreaming(true);
    setCurrentParticipantIndex(0);
    setCurrentRound(roundNumber);
    errorTracking.reset();

    // CRITICAL: Use queueMicrotask to ensure state updates are committed before API call
    // This follows the same pattern as sendMessage to ensure proper message ordering
    queueMicrotask(() => {
      // Trigger streaming with the existing user message
      // Use isParticipantTrigger:true to indicate this is triggering the first participant
      aiSendMessage({
        text: userText,
        metadata: { roundNumber, isParticipantTrigger: true },
      });
    });
  }, [participants, status, messages, errorTracking, isExplicitlyStreaming, aiSendMessage]);

  /**
   * Send a user message and start a new round
   */
  const sendMessage = useCallback(
    async (content: string) => {
      if (status !== 'ready' || isExplicitlyStreaming) {
        return;
      }

      const trimmed = content.trim();
      if (!trimmed) {
        return;
      }

      // AI SDK v5 Pattern: Simple, straightforward participant filtering
      const uniqueParticipants = deduplicateParticipants(participants);
      const enabled = uniqueParticipants.filter(p => p.isEnabled);

      if (enabled.length === 0) {
        throw new Error('No enabled participants');
      }

      // CRITICAL: Update refs FIRST to avoid race conditions
      // These refs are used in prepareSendMessagesRequest and must be set before the API call
      currentIndexRef.current = 0;
      roundParticipantsRef.current = enabled;
      isTriggeringRef.current = false;

      // Use regenerate round number if retrying, otherwise calculate next
      const newRoundNumber = regenerateRoundNumberRef.current !== null
        ? regenerateRoundNumberRef.current
        : calculateNextRoundNumber(messages);

      // CRITICAL: Update round number in ref BEFORE sending message
      // This ensures the backend receives the correct round number
      currentRoundRef.current = newRoundNumber;

      // AI SDK v5 Pattern: Synchronization for proper message ordering
      // Reset all state for new round
      setIsExplicitlyStreaming(true);
      setCurrentParticipantIndex(0);
      setCurrentRound(newRoundNumber);
      errorTracking.reset();

      // CRITICAL FIX: Use queueMicrotask to ensure state updates are committed
      // before the API call is made. This prevents the first participant's response
      // from appearing before the user message during streaming.
      //
      // Without this, React batches state updates and the assistant message
      // can be added to the DOM before the user message is rendered,
      // causing messages to appear in the wrong order during streaming.
      queueMicrotask(() => {
        // Send message without custom ID - let backend generate unique IDs
        aiSendMessage({
          text: trimmed,
          metadata: { roundNumber: newRoundNumber },
        });
      });
    },
    [participants, status, aiSendMessage, messages, errorTracking, isExplicitlyStreaming],
  );

  /**
   * Retry the last round (regenerate entire round from scratch)
   * AI SDK v5 Pattern: Clean state management for round regeneration
   *
   * This completely removes ALL messages from the round (user + assistant)
   * and re-sends the user's prompt to regenerate the round from ground up.
   */
  const retry = useCallback(() => {
    if (status !== 'ready') {
      return;
    }

    // Find the last substantive user message (not a participant trigger)
    const lastUserMessage = messages.findLast((m) => {
      if (m.role !== 'user') {
        return false;
      }

      const metadata = m.metadata as Record<string, unknown> | undefined;
      if (metadata?.isParticipantTrigger) {
        return false;
      }

      const textPart = m.parts?.find(p => p.type === 'text' && 'text' in p);
      const hasContent = textPart && 'text' in textPart && textPart.text.trim().length > 0;

      return hasContent;
    });

    if (!lastUserMessage) {
      return;
    }

    const textPart = lastUserMessage.parts?.find(p => p.type === 'text' && 'text' in p);
    if (!textPart || !('text' in textPart) || !textPart.text.trim()) {
      return;
    }

    // Save the user's prompt text before we delete everything
    const userPromptText = textPart.text;

    const roundNumber = getCurrentRoundNumber(messages);

    // STEP 1: Set regenerate flag to preserve round numbering
    regenerateRoundNumberRef.current = roundNumber;

    // STEP 2: Call onRetry FIRST to remove analysis and cleanup state
    // This must happen before setMessages to ensure UI updates properly
    if (onRetry) {
      onRetry(roundNumber);
    }

    // STEP 3: Remove ALL messages from the current round (user + assistant)
    // Find the first message of the current round and remove everything from that point
    const firstMessageIndexOfRound = messages.findIndex((m) => {
      const metadata = m.metadata as Record<string, unknown> | undefined;
      const msgRoundNumber = metadata?.roundNumber as number | undefined;
      return msgRoundNumber === roundNumber;
    });

    // If we found the round, remove all messages from that point onward
    const messagesBeforeRound = firstMessageIndexOfRound >= 0
      ? messages.slice(0, firstMessageIndexOfRound)
      : messages.slice(0, -1); // Fallback: remove last message if round not found

    setMessages(messagesBeforeRound);

    // STEP 4: Reset streaming state to start fresh
    setIsExplicitlyStreaming(false);

    // CRITICAL: Update ref BEFORE setting state
    currentIndexRef.current = 0;

    // Update participant index synchronously (no flushSync needed)
    setCurrentParticipantIndex(0);

    errorTracking.reset();
    isTriggeringRef.current = false;

    // STEP 5: Send message to start regeneration (as if user just sent the message)
    // This will create a new round with fresh messages (user + assistant)
    // React will batch the state updates naturally
    // The sendMessage function will handle participant orchestration properly
    sendMessage(userPromptText);
  }, [messages, sendMessage, status, setMessages, onRetry, errorTracking]);

  /**
   * Stop the current streaming session
   */
  const stopStreaming = useCallback(() => {
    stop();
    setIsExplicitlyStreaming(false);
    setCurrentParticipantIndex(0);
    isTriggeringRef.current = false;
  }, [stop]);

  /**
   * Reset all hook state
   */
  const resetHookState = useCallback(() => {
    if (isExplicitlyStreaming) {
      // Only reset error tracking during active streaming
      errorTracking.reset();
      return;
    }

    setCurrentParticipantIndex(0);
    roundParticipantsRef.current = [];
    setCurrentRound(1);
    errorTracking.reset();
    regenerateRoundNumberRef.current = null;
    setIsExplicitlyStreaming(false);
    isTriggeringRef.current = false;
  }, [errorTracking, isExplicitlyStreaming]);

  return {
    messages,
    sendMessage,
    startRound,
    isStreaming: isExplicitlyStreaming,
    currentParticipantIndex,
    error: chatError || null,
    retry,
    stop: stopStreaming,
    setMessages,
    resetHookState,
  };
}
